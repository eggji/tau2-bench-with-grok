# Contributing to œÑ¬≤-Bench

Thank you for your interest in contributing to œÑ¬≤-bench! This document provides guidelines to help you make clean, reviewable contributions that can be easily integrated into the project.

## üöÄ Quick Start

1. **Open an Issue First** (recommended): Before starting work, open an issue to discuss your proposed changes
2. **Fork & Clone**: Fork the repository and clone it locally
3. **Follow Branch Conventions**: Use descriptive branch names following our naming conventions
4. **Make Clean Commits**: Write clear commit messages and keep changes focused
5. **Test Your Changes**: Ensure all tests pass and add new tests as needed
6. **Open a Clean PR**: Follow our PR template and guidelines

## üìù Types of Contributions

### Core Framework Contributions
- **Agent implementations**: New agent types or improvements to existing agents
- **Environment enhancements**: Tools, evaluation metrics, or orchestration improvements
- **Performance optimizations**: Caching, parallel processing, or efficiency improvements
- **Bug fixes**: Resolving issues in the core framework

### Domain Contributions
- **New domains**: Complete domain implementations with tasks, tools, and policies
- **Domain improvements**: Enhanced tools, tasks, or policy refinements for existing domains
- **Domain-specific agents**: Specialized agents optimized for particular domains

### Experimental Contributions
- **Research code**: Novel approaches, prototypes, and experimental features
- **Location**: All experimental code goes in `src/experiments/`
- **Requirements**: Each experiment needs its own README with clear documentation
- **Status**: Experimental code is provided as-is and may not be fully supported

### Documentation & Infrastructure
- **Documentation improvements**: README updates, API docs, tutorials
- **Testing enhancements**: New tests, test infrastructure improvements
- **CI/CD improvements**: Workflow enhancements, automation improvements

## üéØ Before You Start: Open an Issue

**We strongly recommend opening an issue before starting work**, especially for:
- New features or significant changes
- New domain implementations
- Large refactoring efforts
- Experimental contributions

### Issue Template
When opening an issue, please include:
- **Problem/Goal**: What problem are you solving or what feature are you adding?
- **Proposed Solution**: High-level approach you plan to take
- **Impact**: What components will be affected?
- **Timeline**: Expected development timeline
- **Dependencies**: Any external dependencies or blockers

This helps us:
- Provide early feedback and guidance
- Avoid duplicate work
- Ensure alignment with project goals
- Suggest the best approach for your contribution

## üåø Branch Naming Conventions

Use clear, descriptive branch names following these patterns:

### Core Framework Changes
- `feature/description` - New features
- `fix/issue-description` - Bug fixes
- `refactor/component-name` - Code refactoring
- `perf/optimization-description` - Performance improvements

### Domain-Specific Changes
- `domain/domain-name/feature-description` - New domain or domain features
- `domain/domain-name/fix-description` - Domain bug fixes

### Experimental Contributions
- `experiment/experiment-name` - New experimental features
- `experiment/experiment-name/enhancement` - Improvements to existing experiments

### Documentation & Infrastructure
- `docs/description` - Documentation updates
- `test/description` - Test improvements
- `ci/description` - CI/CD improvements

### Examples
```bash
# Good branch names
feature/agent-memory-system
fix/environment-tool-timeout
domain/healthcare/patient-lookup-tools
experiment/multi-agent-collaboration
docs/contributing-guide-update
test/domain-integration-tests

# Avoid
my-changes
fix
update
new-stuff
```

## üîß Development Setup

### 1. Environment Setup
```bash
# Clone your fork
git clone https://github.com/your-username/tau2-bench.git
cd tau2-bench

# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install in development mode
pip install -e .

# Verify installation
tau2 check-data
```

### 2. Development Dependencies
The project uses several tools for code quality:
- **Ruff**: Linting and code formatting
- **pytest**: Testing framework
- **PDM**: Package management

### 3. Environment Variables
Copy `.env.example` to `.env` and configure your API keys for testing.

## üß™ Testing Requirements

### Running Tests
```bash
# Run all tests
make test

# Run specific test categories
pytest tests/test_domains/  # Domain tests
pytest tests/test_agent.py  # Agent tests
pytest tests/test_environment.py  # Environment tests
```

### Test Requirements for PRs
- **Existing tests must pass**: All current tests should continue to pass
- **New functionality needs tests**: Add tests for new features or bug fixes
- **Domain contributions**: Include comprehensive domain-specific tests
- **Experimental code**: Basic smoke tests recommended but not required

### Test Coverage Guidelines
- **Core framework changes**: Aim for good test coverage of new functionality
- **Domain implementations**: Test all tools, tasks, and policy interactions
- **Bug fixes**: Include regression tests to prevent the bug from reoccurring

## üìã Code Quality Standards

### Code Formatting and Linting
We use **Ruff** for both linting and formatting:

```bash
# Check linting
make lint

# Format code
make format

# Auto-fix linting issues
make lint-fix

# Run both linting and formatting
make check-all
```

### Code Style Guidelines
- **Line length**: 88 characters (configured in pyproject.toml)
- **Import organization**: Use Ruff's import sorting
- **Type hints**: Encouraged for new code, especially in core framework
- **Docstrings**: Required for public APIs and complex functions

### Commit Message Guidelines
Write clear, concise commit messages:
```bash
# Good commit messages
feat: add memory system to agent base class
fix: resolve environment tool timeout issues
docs: update domain contribution guidelines
test: add integration tests for retail domain

# Avoid
fixed stuff
updates
wip
```

## üîç Pull Request Guidelines

### Before Opening a PR
- [ ] All tests pass locally (`make test`)
- [ ] Code follows style guidelines (`make check-all` passes)
- [ ] New functionality is tested
- [ ] Documentation is updated if needed
- [ ] Commit messages are clear and descriptive

### PR Title and Description
**Title Format**: `type: brief description`

**Description Template**:
```markdown
## Summary
Brief description of the changes made.

## Changes Made
- List of specific changes
- Include any breaking changes
- Note any new dependencies

## Testing
- How you tested the changes
- What test cases were added/modified
- Any manual testing performed

## Documentation
- Any documentation updates made
- Links to relevant docs or issues

## Checklist
- [ ] Tests pass (`make test`)
- [ ] Code follows style guidelines (`make check-all`)
- [ ] Documentation updated
- [ ] Breaking changes noted
```

### PR Review Process
1. **Automated checks**: CI tests and code quality checks must pass
2. **Maintainer review**: Code review focusing on:
   - Correctness and functionality
   - Code quality and maintainability
   - Test coverage and documentation
   - Alignment with project goals
3. **Feedback incorporation**: Address review feedback promptly
4. **Final approval**: Maintainer approval required for merge

## üéØ Specific Contribution Guidelines

### Domain Contributions
When contributing a new domain:
- **Complete implementation**: Include all required components (tools, tasks, policy, tests)
- **Documentation**: Comprehensive README with domain overview, API docs, and examples
- **Test coverage**: Full test suite covering all domain functionality
- **Data validation**: Ensure all domain data is properly validated

### Experimental Contributions
For `src/experiments/` contributions:
- **Self-contained**: Keep experimental code isolated within the experiments directory
- **Documentation**: Include detailed README explaining the experiment and usage
- **Dependencies**: Manage dependencies carefully to avoid conflicts with core framework
- **Status clarity**: Clearly mark experimental status and limitations

### Agent Contributions
When contributing new agent implementations:
- **Interface compliance**: Follow the base agent interface
- **Configuration**: Support standard configuration patterns
- **Error handling**: Robust error handling and logging
- **Documentation**: Clear usage examples and configuration options

## ü§ù Getting Help

- **GitHub Issues**: For bugs, feature requests, and general questions
- **Documentation**: Check existing docs and README files first

## üìú Code of Conduct

- Be respectful and constructive in all interactions
- Focus on the technical aspects of contributions
- Help maintain a welcoming environment for all contributors
- Follow generally accepted open source collaboration practices

## üéâ Recognition

Contributors who make significant contributions may be:
- Added to the project's contributor list
- Mentioned in release notes

Thank you for contributing to œÑ¬≤-bench! Your efforts help advance the field of conversational AI evaluation.
